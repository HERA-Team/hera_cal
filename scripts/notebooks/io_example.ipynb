{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# I/O using `HERAData` and `HERACal`\n",
    "\n",
    "by Josh Dillon (jsdillon@berkeley.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:18.053697Z",
     "start_time": "2018-08-28T16:57:15.708561Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import os\n",
    "from hera_cal.io import HERAData, HERACal\n",
    "from hera_cal.data import DATA_PATH\n",
    "uvh5_file_1 = os.path.join(DATA_PATH, \"zen.2458116.61019.xx.HH.h5XRS_downselected\")\n",
    "uvh5_file_2 = os.path.join(DATA_PATH, \"zen.2458116.61765.xx.HH.h5XRS_downselected\")\n",
    "miriad_file = os.path.join(DATA_PATH, \"zen.2458043.12552.xx.HH.uvORA\")\n",
    "calfits_file = os.path.join(DATA_PATH, \"test_input/zen.2457698.40355.xx.HH.uvc.omni.calfits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T00:20:29.472259Z",
     "start_time": "2018-07-12T00:20:29.466227Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Reading and writing data with `HERAData`\n",
    "\n",
    "`HERAData` is a subclass of `pyuvdata.UVData` with streamlined interfaces and additional functionality for producing and ingesting `DataContainer`s, the standard in-memory format for `hera_cal`. The standard syntax for loading an entire file is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:19.221627Z",
     "start_time": "2018-08-28T16:57:19.112699Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hd = HERAData(uvh5_file_1)\n",
    "data, flags, nsamples = hd.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "`data`, `flags`, and `nsamples` are `DataContainer`s and they include ***copies*** of data in the HERAData object. They work like dictionaries, mapping 3-tuples of the form `(0, 1, 'xx')` to waterfalls of shape `(Nint, Nfreq)`. They know to conjugate data when you ask for the reverse baseline are agnostic as to the capitalization convention for the polarization string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:21.920893Z",
     "start_time": "2018-08-28T16:57:21.912217Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(53, 53, 'xx'), (53, 54, 'xx'), (54, 54, 'xx')]\n",
      "(60, 1024)\n",
      "(-16.241686+56.264435j)\n",
      "(-16.241686-56.264435j)\n",
      "(-16.241686-56.264435j)\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "print(data[53, 54, 'xx'].shape)\n",
    "print(data[53, 54, 'xx'][0,0])\n",
    "print(data[54, 53, 'XX'][0,0])\n",
    "print(data[54, 53, 'xx'][0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "A new feature is that the `DataContainer`s now include a bunch of useful metadata as class attributes. This includes:\n",
    "* `data.antpos`: a dictionary that maps antenna number to position in meters\n",
    "* `data.freqs`: a numpy array of the frequencies in Hz\n",
    "* `data.times`: a numpy array of the unique times in the data in JD\n",
    "* `data.lsts`: a numpy array of the unique LSTs in the data in radians\n",
    "* `data.times_by_bl`: a dictionary that maps antenna pairs to JDs (will be useful for baseline-dependant averaging)\n",
    "* `data.lsts_by_bl`: a dictionary that maps antenna pairs to LSTS (will be useful for baseline-dependant averaging)\n",
    "\n",
    "`HERAData`'s preferred (and defualt) format is `uvh5`, which is based on HDF5. When using this format, useful metadata about the whole file is stored `HERAData` object and it does not change when a partial data read is performed. `HERAData` also supports loading `miriad` and `uvfits`, but they do not get this useful whole-file metadata saved internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:24.364196Z",
     "start_time": "2018-08-28T16:57:22.275206Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "useful metadata: ['ants', 'antpos', 'freqs', 'times', 'lsts', 'pols', 'antpairs', 'bls', 'times_by_bl', 'lsts_by_bl']\n",
      "uvh5 hd.freqs: [1.00000000e+08 1.00097656e+08 1.00195312e+08 ... 1.99707031e+08\n",
      " 1.99804688e+08 1.99902344e+08]\n",
      "miriad hd.freqs: None\n"
     ]
    }
   ],
   "source": [
    "hd = HERAData(uvh5_file_1)\n",
    "print('useful metadata:', hd.HERAData_metas)\n",
    "print('uvh5 hd.freqs:', hd.freqs)\n",
    "\n",
    "hd = HERAData(miriad_file, filetype='miriad')\n",
    "print('miriad hd.freqs:', hd.freqs)\n",
    "data, flags, nsamples = hd.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "`HERAData` also supports loading of lists of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:24.556462Z",
     "start_time": "2018-08-28T16:57:24.368835Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 1024)\n"
     ]
    }
   ],
   "source": [
    "hd = HERAData([uvh5_file_1, uvh5_file_2])\n",
    "data, flags, nsamples = hd.read()\n",
    "print(data[53, 54, 'xx'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Going from DataContainers back to HERAData\n",
    "\n",
    "`HERAData.read()` produces copies of the data in `DataContainer`s. To put data back in the internal data arrays, e.g. in preparation for writing out a file, use `update()`. Then once can use standard `UVData` write functionality, like `write_uvh5()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:24.661808Z",
     "start_time": "2018-08-28T16:57:24.561461Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hd = HERAData(uvh5_file_1)\n",
    "data, flags, nsamples = hd.read()\n",
    "# do stuff here\n",
    "hd.update(data=data, flags=flags, nsamples=nsamples)\n",
    "hd.write_uvh5('new_file.uvh5', clobber=True)\n",
    "os.remove('new_file.uvh5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Partial Data Loading\n",
    "\n",
    "`HERAData` is designed with partial data loading in mind. It supports partial data loading by baseline, polarization, time, frequency, and channel (though the last three don't work as well in miriad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:24.741440Z",
     "start_time": "2018-08-28T16:57:24.666524Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of baselines: 2\n",
      "waterfall shape: (20, 100)\n"
     ]
    }
   ],
   "source": [
    "hd = HERAData(uvh5_file_1)\n",
    "data, flags, nsamples = hd.read(bls=[(53, 54, 'xx'), (54, 54, 'xx')], frequencies=hd.freqs[100:200], times=hd.times[0:20])\n",
    "print('number of baselines:', len(data))\n",
    "print('waterfall shape:', data[(53, 54, 'xx')].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Partial data reads replace rather than add to the data stored in the HERAData object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Iterators\n",
    "\n",
    "This sort of partial data loading is made easier by useful methods for looping over an entire datafile. For example, if we want to iterate over frequencies 300 at a time, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:25.002044Z",
     "start_time": "2018-08-28T16:57:24.745748Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial load shape: (60, 300)\n",
      "Partial load shape: (60, 300)\n",
      "Partial load shape: (60, 300)\n",
      "Partial load shape: (60, 124)\n"
     ]
    }
   ],
   "source": [
    "hd = HERAData(uvh5_file_1)\n",
    "for data, flags, nsamples in hd.iterate_over_freqs(Nchans=300):\n",
    "    # do stuff here\n",
    "    print('Partial load shape:', data[hd.bls[0]].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "This funcationality, and the analogous `iterate_over_bls()` and `iterate_over_times()` are by default only available for `uvh5`-initialized `HERAData` objects because only they simultaneously know the dimensions of the full file and of the current subset of the file loaded into memory. However it is possible to manually provide the list to iterator over when using other formats. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:25.589713Z",
     "start_time": "2018-08-28T16:57:25.006105Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baselines loaded: [(52, 52, 'xx'), (52, 53, 'xx')]\n",
      "Baselines loaded: [(53, 53, 'xx')]\n"
     ]
    }
   ],
   "source": [
    "hd = HERAData(miriad_file, filetype='miriad')\n",
    "for data, flags, nsamples in hd.iterate_over_bls(Nbls=2, bls=[(52, 52, 'xx'), (52, 53, 'xx'), (53, 53, 'xx')]):\n",
    "    # do stuff here\n",
    "    print('Baselines loaded:', data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Partial Data Writing\n",
    "\n",
    "`uvh5` files now support partial data writing. As its enabled by HERAData, this produces an empty data file the same size as the input `uvh5` file and then writes a part of it corresponding to the last partial `read()` (iterators also call `read()` at each iterateration). The part of the data that is written will thus have the same dimensions as the data read most recently. So, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:26.079083Z",
     "start_time": "2018-08-28T16:57:25.594022Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now writing 100.0 to 129.19921875 MHz\n",
      "Now writing 129.296875 to 158.49609375 MHz\n",
      "Now writing 158.59375 to 187.79296875 MHz\n",
      "Now writing 187.890625 to 199.90234375 MHz\n"
     ]
    }
   ],
   "source": [
    "hd = HERAData(uvh5_file_1)\n",
    "for data, flags, nsamples in hd.iterate_over_freqs(Nchans=300):\n",
    "    # do stuff here\n",
    "    hd.partial_write('new_file.uvh5', data=data, flags=flags, nsamples=nsamples, clobber=True)\n",
    "    print('Now writing', data.freqs[0]/1e6, 'to', data.freqs[-1]/1e6, 'MHz')\n",
    "os.remove('new_file.uvh5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Reading and writing calibration solutions with `HERACal`\n",
    "\n",
    "Analogous to the new `HERAData` module, we've also subclassed `pyuvdata.UVCal` into `HERACal` which operates in a similar way, though it is far less fully featured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:26.129016Z",
     "start_time": "2018-08-28T16:57:26.083585Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hc = HERACal(calfits_file)\n",
    "gains, flags, quals, total_qual = hc.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "`HERACal`'s read produces dictionaries that map antenna-pol tuples to gain waterfalls of N \n",
    "\n",
    "Theses are:\n",
    "* `gains`: dict mapping antenna-pol keys to (Nint, Nfreq) complex gains arrays\n",
    "* `flags`: dict mapping antenna-pol keys to (Nint, Nfreq) boolean flag arrays\n",
    "* `quals`: dict mapping antenna-pol keys to (Nint, Nfreq) float qual arrays\n",
    "* `total_qual:` dict mapping polarization to (Nint, Nfreq) float total quality array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:26.138602Z",
     "start_time": "2018-08-28T16:57:26.133630Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 'Jxx'), (10, 'Jxx'), (20, 'Jxx'), (22, 'Jxx'), (31, 'Jxx'), (43, 'Jxx'), (53, 'Jxx'), (64, 'Jxx'), (65, 'Jxx'), (72, 'Jxx'), (80, 'Jxx'), (88, 'Jxx'), (89, 'Jxx'), (96, 'Jxx'), (97, 'Jxx'), (104, 'Jxx'), (105, 'Jxx'), (112, 'Jxx')]\n",
      "(3, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(gains.keys())\n",
    "print(gains[(9, 'Jxx')].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Unlike DataContainers, these dictionaries have no special metadata stored internally. However, the HERACal object generates a variety of useful metadata that is stored internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:26.152015Z",
     "start_time": "2018-08-28T16:57:26.143615Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies: 100.0 to 199.90234375\n",
      "Times: 2457698.403551911 to 2457698.403800471\n",
      "Antennas: [(9, 'Jxx'), (10, 'Jxx'), (20, 'Jxx'), (22, 'Jxx'), (31, 'Jxx'), (43, 'Jxx'), (53, 'Jxx'), (64, 'Jxx'), (65, 'Jxx'), (72, 'Jxx'), (80, 'Jxx'), (88, 'Jxx'), (89, 'Jxx'), (96, 'Jxx'), (97, 'Jxx'), (104, 'Jxx'), (105, 'Jxx'), (112, 'Jxx')]\n",
      "Pols: ['Jxx']\n"
     ]
    }
   ],
   "source": [
    "print('Frequencies:', hc.freqs[0]/1e6, 'to', hc.freqs[-1]/1e6)\n",
    "print('Times:', hc.times[0], 'to', hc.times[-1])\n",
    "print('Antennas:', hc.ants)\n",
    "print('Pols:', hc.pols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "To put data from dictionaries back into `HERACal` objects, again one uses the `update()` function, followed by the standard `pyuvdata.UVCal` write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T16:57:26.235699Z",
     "start_time": "2018-08-28T16:57:26.156702Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hc = HERACal(calfits_file)\n",
    "gains, flags, quals, total_qual = hc.read()\n",
    "# do stuff here\n",
    "hc.update(gains=gains, flags=flags, quals=quals, total_qual=total_qual)\n",
    "hc.write_calfits('new_file.calfits')\n",
    "os.remove('new_file.calfits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "For now, there are no plans to support partial reading or writing for `HERACal` or any other calibration formats besides `calfits`. However, the HERAData example gives us clear mode of operation if we were to persure that option in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
